{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类准确率：  0.92\n",
      "         Y_pre      Y_true\n",
      "0   spec_prior  spec_prior\n",
      "1     priority    priority\n",
      "2   spec_prior  spec_prior\n",
      "3     priority    priority\n",
      "4   spec_prior  spec_prior\n",
      "5     priority    priority\n",
      "6   spec_prior  spec_prior\n",
      "7    not_recom   not_recom\n",
      "8     priority    priority\n",
      "9   spec_prior  spec_prior\n",
      "10    priority    priority\n",
      "11  spec_prior  spec_prior\n",
      "12    priority    priority\n",
      "13    priority    priority\n",
      "14    priority    priority\n",
      "15  spec_prior  spec_prior\n",
      "16  spec_prior  spec_prior\n",
      "17   not_recom   not_recom\n",
      "18   not_recom   not_recom\n",
      "19  spec_prior  spec_prior\n",
      "20    priority    priority\n",
      "21  spec_prior    priority\n",
      "22   not_recom   not_recom\n",
      "23   not_recom   not_recom\n",
      "24    priority    priority\n",
      "25   not_recom   not_recom\n",
      "26    priority    priority\n",
      "27   not_recom   not_recom\n",
      "28   not_recom   not_recom\n",
      "29  spec_prior  spec_prior\n",
      "..         ...         ...\n",
      "70   not_recom   not_recom\n",
      "71   not_recom   not_recom\n",
      "72  spec_prior  spec_prior\n",
      "73   not_recom   not_recom\n",
      "74  spec_prior  spec_prior\n",
      "75    priority    priority\n",
      "76   not_recom   not_recom\n",
      "77    priority    priority\n",
      "78   not_recom   not_recom\n",
      "79    priority  spec_prior\n",
      "80    priority    priority\n",
      "81    priority    priority\n",
      "82   not_recom   not_recom\n",
      "83  spec_prior  spec_prior\n",
      "84   not_recom   not_recom\n",
      "85  spec_prior  spec_prior\n",
      "86  spec_prior  spec_prior\n",
      "87    priority    priority\n",
      "88    priority  spec_prior\n",
      "89    priority    priority\n",
      "90    priority    priority\n",
      "91  spec_prior  spec_prior\n",
      "92    priority    priority\n",
      "93   not_recom   not_recom\n",
      "94    priority    priority\n",
      "95   not_recom   not_recom\n",
      "96   not_recom   not_recom\n",
      "97    priority    priority\n",
      "98    priority    priority\n",
      "99   not_recom   not_recom\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def naiveBayesTrain(X,Y,data):\n",
    "    lambd = 1\n",
    "    dictY = Y.groupby(['label']).size().reset_index(name='Size')\n",
    "    labelCount = dictY.shape[0]\n",
    "    labelSize = dictY.sum().values[1]\n",
    "    dictY['probability'] = dictY['Size'].apply(lambda x: (x + lambd) / (labelSize + labelCount * lambd))\n",
    "    featureDict = {}\n",
    "    for key in X.columns.tolist():\n",
    "        temp = data.groupby([key,'label']).size().reset_index(name='Size').pivot(key,'label','Size').fillna(0)\n",
    "        for label_key in temp.columns.tolist():\n",
    "            temp[label_key] = temp[label_key].apply(lambda x: (x + lambd) / (temp[label_key].sum() + temp.shape[0] * lambd))\n",
    "        featureDict[key] = temp\n",
    "    return featureDict,dictY\n",
    "\n",
    "def naiveBayesPredict(X_pre,featureDict,labelList,dictY):\n",
    "    Y_pre = []\n",
    "    columnsList = X_pre.columns.tolist()\n",
    "    for i in range(X_pre.shape[0]):\n",
    "        resultList = []\n",
    "        feaList = X_pre.iloc[i].reset_index(name='feaValues').rename(columns={'index':'feaName'})\n",
    "        for labelKey in labelList:\n",
    "            temProbability = 0\n",
    "            for columnkey in columnsList:\n",
    "                feaValue = feaList[feaList['feaName'] == columnkey].values[0][1]\n",
    "                temProbability += math.log(featureDict[columnkey].loc[feaValue][labelKey])\n",
    "            resultList.append(temProbability + math.log(dictY[dictY['label'] == labelKey]['probability'].values[0]))\n",
    "        Y_pre.append(labelList[resultList.index(max(resultList))])\n",
    "    return pd.DataFrame(Y_pre,columns=['label'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv('/Users/world/课程资料/数据分析工具实践/第三次作业/第3次作业/贝叶斯/数据/nursery.data',header=None)\n",
    "    data.columns=['parents','has_nurs','form','children','housing','finance','social','health','label']\n",
    "    dataPre = data.sample(n=100).reset_index(drop=True)\n",
    "    X = data.drop(['label'],axis=1)\n",
    "    Y = pd.DataFrame(data['label'])\n",
    "    labelList = Y.groupby(['label']).count().index.tolist()\n",
    "    featureDict, dictY = naiveBayesTrain(X,Y,data)\n",
    "    X_pre = dataPre.drop(['label'],axis=1)\n",
    "    Y_pre= naiveBayesPredict(X_pre,featureDict,labelList,dictY)\n",
    "    Y_true = pd.DataFrame(dataPre['label'])\n",
    "    temp = pd.concat([Y_pre,Y_true],axis=1)\n",
    "    temp.columns = ['Y_pre','Y_true']\n",
    "    print(\"分类准确率： \", accuracy_score(Y_true, Y_pre))\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8174086378737541\n",
      "    Y_pre  T_true\n",
      "0     1.0       1\n",
      "1     0.0       1\n",
      "2     1.0       1\n",
      "3     0.0       1\n",
      "4     1.0       1\n",
      "5     1.0       1\n",
      "6     1.0       1\n",
      "7     1.0       1\n",
      "8     0.0       1\n",
      "9     1.0       1\n",
      "10    0.0       1\n",
      "11    1.0       1\n",
      "12    0.0       1\n",
      "13    1.0       1\n",
      "14    1.0       1\n",
      "15    0.0       0\n",
      "16    0.0       1\n",
      "17    1.0       1\n",
      "18    1.0       1\n",
      "19    1.0       0\n",
      "20    1.0       1\n",
      "21    0.0       1\n",
      "22    1.0       1\n",
      "23    1.0       1\n",
      "24    1.0       1\n",
      "25    1.0       1\n",
      "26    0.0       1\n",
      "27    1.0       1\n",
      "28    1.0       1\n",
      "29    1.0       1\n",
      "30    0.0       1\n",
      "31    1.0       0\n",
      "32    1.0       1\n",
      "33    1.0       1\n",
      "34    1.0       1\n",
      "35    1.0       1\n",
      "36    1.0       1\n",
      "37    1.0       1\n",
      "38    1.0       1\n",
      "39    1.0       1\n",
      "40    1.0       1\n",
      "41    1.0       1\n",
      "42    1.0       1\n",
      "43    1.0       1\n",
      "44    1.0       1\n",
      "45    1.0       1\n",
      "46    1.0       1\n",
      "47    1.0       1\n",
      "48    0.0       1\n",
      "49    1.0       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def sigmoid(inX):\n",
    "    return 1.0 / (1 + np.exp(-inX))\n",
    "\n",
    "def gradAscent(X, Y):\n",
    "    dataMatrix = np.mat(X)\n",
    "    labelMat = np.mat(Y).transpose()\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    alpha = 0.01\n",
    "    maxCycles = 500\n",
    "    weights = np.ones((n,1))\n",
    "    weights_array = np.array([])\n",
    "    for k in range(maxCycles):\n",
    "        h = sigmoid(dataMatrix * weights)\n",
    "        error = labelMat - h\n",
    "        weights = weights + alpha * dataMatrix.transpose() * error\n",
    "        weights_array = np.append(weights_array,weights)\n",
    "    weights_array = weights_array.reshape(maxCycles,n)\n",
    "    return weights.getA(),weights_array\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_excel(\"./第3次作业/回归算法/2014 and 2015 CSM dataset.xlsx\")\n",
    "    data = data.dropna(axis=0,how='any').reset_index(drop=True)\n",
    "    dataPre = data.sample(n=50).reset_index(drop=True)\n",
    "    X = data.drop(['Movie','Ratings'],axis=1)\n",
    "    Y = data['Ratings'].apply(lambda x: (0,1)[x>5])\n",
    "    weights,weights_array = gradAscent(X, Y)\n",
    "    X_pre = dataPre.drop(['Movie','Ratings'],axis=1)\n",
    "    Y_true = dataPre['Ratings'].apply(lambda x: (0,1)[x>5])\n",
    "    Y_pre = sigmoid(np.dot(X_pre,weights)).tolist()\n",
    "    Y_pre = pd.Series([x[0] for x in Y_pre])\n",
    "    print('准确率：', metrics.f1_score(Y_true, Y_pre, average='weighted'))\n",
    "    temp = pd.concat([Y_pre,Y_true],axis=1)\n",
    "    temp.columns = ['Y_pre','T_true']\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
